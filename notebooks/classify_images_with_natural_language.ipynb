{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIpyR7i-XtMy"
      },
      "source": [
        "~~~\n",
        "Copyright 2024 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n",
        "~~~\n",
        "\u003ctable\u003e\u003ctbody\u003e\u003ctr\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://colab.research.google.com/github/google-health/cxr-foundation/blob/master/notebooks/classify_images_with_natural_language.ipynb\"\u003e\n",
        "      \u003cimg alt=\"Google Colab logo\" src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" width=\"32px\"\u003e\u003cbr\u003e Run in Google Colab\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Fgoogle-health%2Fcxr-foundation%2Fmaster%2Fnotebooks%2Fclassify_images_with_natural_language.ipynb\"\u003e\n",
        "      \u003cimg alt=\"Google Cloud Colab Enterprise logo\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" width=\"32px\"\u003e\u003cbr\u003e Run in Colab Enterprise\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://github.com/google-health/cxr-foundation/blob/master/notebooks/classify_images_with_natural_language.ipynb\"\u003e\n",
        "      \u003cimg alt=\"GitHub logo\" src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" width=\"32px\"\u003e\u003cbr\u003e View on GitHub\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "  \u003ctd style=\"text-align: center\"\u003e\n",
        "    \u003ca href=\"https://huggingface.co/google/cxr-foundation\"\u003e\n",
        "      \u003cimg alt=\"HuggingFace logo\" src=\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\" width=\"32px\"\u003e\u003cbr\u003e View on HuggingFace\n",
        "    \u003c/a\u003e\n",
        "  \u003c/td\u003e\n",
        "\u003c/tr\u003e\u003c/tbody\u003e\u003c/table\u003e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTTGbllChDdY"
      },
      "source": [
        "# CXR Foundation Zero-shot Classification Demo\n",
        "\n",
        "This notebook demonstrates how to use embeddings from the CXR Foundation model to perform zero-shot classification of chest X-ray images. The notebook covers the following:\n",
        "\n",
        "\n",
        "- Downloading 2737 precomputed embeddings and labels for a subset of the open-access NIH Chest X-ray14 (CXR-14) dataset.\n",
        "- Performing text-based zero-shot classification of diseases using these embeddings.\n",
        "- Evaluating the classification performance using AUC by comparing to the [CXR-14 labels](https://pmc.ncbi.nlm.nih.gov/articles/PMC10607847/).\n",
        "- Exploring the impact of different text prompts on the classification results.\n",
        "\n",
        "The embeddings used in this demo are the *all_contrastive_img_emb* embeddings, which are text-aligned image embeddings from the Q-former output in [ELIXR-B](https://arxiv.org/abs/2308.01317). These embeddings have been precomputed to streamline the demonstration and eliminate the need for lengthy downloads.\n",
        "\n",
        "**Note:** The CXR-14 labels used in this demo were generated through text mining and may have limitations. For more information on generating embeddings using the CXR Foundation model, refer to the [HuggingFace model card](https://huggingface.co/google/cxr-foundation), or using this [quickstart colab](https://colab.research.google.com/github/google-health/cxr-foundation/blob/master/notebooks/quick_start_with_hugging_face.ipynb).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axuHyjBaxWva"
      },
      "source": [
        "# Authenticate to Access Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-t2zwPufcyyl"
      },
      "outputs": [],
      "source": [
        "# @title Authenticate with HuggingFace, skip if you have a HF_TOKEN secret\n",
        "\n",
        "# Authenticate user for HuggingFace if needed. Enter token below if requested.\n",
        "from huggingface_hub.utils import HfFolder\n",
        "\n",
        "if HfFolder.get_token() is None:\n",
        "    from huggingface_hub import notebook_login\n",
        "    notebook_login()\n",
        "else:\n",
        "    print(\"Token already set\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Evn9WNBSd-CP"
      },
      "outputs": [],
      "source": [
        "# @title Download precomputed embeddings and labels from HuggingFace\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "HF_REPO_ID = \"google/cxr-foundation\"\n",
        "\n",
        "# Download precomputed embeddings.\n",
        "EMBEDDINGS_NPZ_FILE_PATH = hf_hub_download(repo_id=HF_REPO_ID, filename='embeddings.npz', subfolder='precomputed_embeddings')\n",
        "embeddings_file = np.load(EMBEDDINGS_NPZ_FILE_PATH)\n",
        "image_embeddings_df = pd.DataFrame(\n",
        "    [(key, embeddings_file[key]) for key in embeddings_file.keys()],\n",
        "    columns=['image_id', 'embeddings']\n",
        ")\n",
        "embeddings_file.close()\n",
        "\n",
        "# Download precomputed text embeddings.\n",
        "TEXT_EMBEDDINGS_NPZ_FILE_PATH = hf_hub_download(repo_id=HF_REPO_ID, filename='text_embeddings.npz', subfolder='precomputed_embeddings')\n",
        "\n",
        "# Download the labels file to annotate the outputs.\n",
        "LABEL_FILE_PATH = hf_hub_download(repo_id=HF_REPO_ID, filename='labels.csv', subfolder='precomputed_embeddings')\n",
        "\n",
        "# Read text embeddings\n",
        "text_embeddings_file = np.load(TEXT_EMBEDDINGS_NPZ_FILE_PATH)\n",
        "text_embeddings_queries = list(text_embeddings_file.keys())\n",
        "text_embeddings_df = pd.DataFrame(\n",
        "    [(key, text_embeddings_file[key]) for key in text_embeddings_file.keys()],\n",
        "    columns=['query', 'embeddings']\n",
        ")\n",
        "text_embeddings_file.close()\n",
        "\n",
        "# Read labels\n",
        "full_labels_df = pd.read_csv(LABEL_FILE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sJHxx4cvxswM"
      },
      "outputs": [],
      "source": [
        "# @title Similarity and Zero-shot Classification Functions\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load labels\n",
        "labels_df = pd.read_csv(LABEL_FILE_PATH)\n",
        "diagnosis_columns = ['AIRSPACE_OPACITY', 'PNEUMOTHORAX', 'EFFUSION', 'PULMONARY_EDEMA']\n",
        "\n",
        "def softmax(x):\n",
        "    \"\"\"Calculates the softmax of a list of numbers.\"\"\"\n",
        "    exp_x = np.exp(x - np.max(x))  # Subtract max for numerical stability\n",
        "    return exp_x / exp_x.sum(axis=0)\n",
        "\n",
        "def compute_image_text_similarity(image_emb, txt_emb):\n",
        "  image_emb = np.reshape(image_emb, (32, 128))\n",
        "  similarities = []\n",
        "  for i in range(32):\n",
        "    # cosine similarity\n",
        "    similarity = np.dot(image_emb[i], txt_emb)/(np.linalg.norm(image_emb[i]) * np.linalg.norm(txt_emb))\n",
        "    similarities.append(similarity)\n",
        "  np_sm_similarities = np.array((similarities))\n",
        "  return np.max(np_sm_similarities)\n",
        "\n",
        "def zero_shot(image_emb, pos_txt_emb,neg_txt_emb):\n",
        "  pos_cosine = compute_image_text_similarity(image_emb, pos_txt_emb)\n",
        "  neg_cosine = compute_image_text_similarity(image_emb, neg_txt_emb)\n",
        "  return pos_cosine - neg_cosine\n",
        "\n",
        "def get_text_embeddings_for_diagnosis(diagnosis):\n",
        "  \"\"\"\n",
        "  This function takes a diagnosis as input and outputs the positive and negative text queries.\n",
        "  \"\"\"\n",
        "  column_to_pos_neg = {\n",
        "      'AIRSPACE_OPACITY': ('Airspace Opacity', 'no evidence of airspace disease'),\n",
        "      'PNEUMOTHORAX': ('small pneumothorax', 'no pneumothorax'),\n",
        "      'EFFUSION': ('large pleural effusion', 'no pleural effusion'),\n",
        "      'PULMONARY_EDEMA': ('moderate pulmonary edema', 'no pulmonary edema'),\n",
        "  }\n",
        "\n",
        "  pos_txt, neg_txt = column_to_pos_neg[diagnosis]\n",
        "\n",
        "\n",
        "  return pos_txt, neg_txt\n",
        "\n",
        "def compute_similarity_scores(eval_data_df, pos_txt, neg_txt):\n",
        "  pos_txt_emb = text_embeddings_df.set_index('query').loc[pos_txt, 'embeddings']\n",
        "  neg_txt_emb = text_embeddings_df.set_index('query').loc[neg_txt, 'embeddings']\n",
        "\n",
        "  # Iterate over each image_id in eval_data_df\n",
        "  for index, row in eval_data_df.iterrows():\n",
        "    image_id = row['image_id']\n",
        "    # Get the embedding for the current image_id from image_embeddings_df\n",
        "    image_embedding = image_embeddings_df[image_embeddings_df['image_id'] == image_id]['embeddings'].iloc[0]\n",
        "    # Compute the similarity using the zero_shot function\n",
        "    similarity_score = zero_shot(image_embedding, pos_txt_emb, neg_txt_emb)\n",
        "    # Store the similarity score in a new column named 'score'\n",
        "    eval_data_df.loc[index, 'score'] = similarity_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "jR4NEOwzu-q7"
      },
      "outputs": [],
      "source": [
        "# @title Evaluate and graph AUC\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "diagnosis_dropdown = widgets.Dropdown(\n",
        "    options=diagnosis_columns,\n",
        "    description='Diagnosis:',\n",
        "    disabled=False,\n",
        ")\n",
        "\n",
        "text_input_pos = widgets.Combobox(\n",
        "    placeholder='Type positive text...',\n",
        "    options=text_embeddings_queries,\n",
        "    ensure_option=True  # Ensures that the typed value is in the options\n",
        ")\n",
        "\n",
        "text_input_neg = widgets.Combobox(\n",
        "    placeholder='Type negative text...',\n",
        "    options=text_embeddings_queries,\n",
        "    ensure_option=True  # Ensures that the typed value is in the options\n",
        ")\n",
        "\n",
        "clear_button_pos = widgets.Button(description=\"Change Positive Text\")\n",
        "clear_button_neg = widgets.Button(description=\"Change Negative Text\")\n",
        "clear_button_pos.on_click(lambda b: text_input_pos.set_trait('value', ''))\n",
        "clear_button_neg.on_click(lambda b: text_input_neg.set_trait('value', ''))\n",
        "\n",
        "processing = False\n",
        "\n",
        "def draw_auc_plot(column, pos_txt = None, neg_txt = None):\n",
        "  if pos_txt == '' or neg_txt == '':\n",
        "    return\n",
        "  global processing\n",
        "  if processing:\n",
        "    return\n",
        "  processing = True\n",
        "  clear_output(True)\n",
        "  print('Computing, please wait')\n",
        "  if pos_txt is None:\n",
        "    pos_txt, neg_txt = get_text_embeddings_for_diagnosis(column)\n",
        "    text_input_pos.value = pos_txt\n",
        "    text_input_neg.value = neg_txt\n",
        "\n",
        "  eval_data_df = labels_df[labels_df[column].isin([0, 1])][['image_id', column]].copy()\n",
        "  eval_data_df.rename(columns={column: 'label'}, inplace=True)\n",
        "\n",
        "  compute_similarity_scores(eval_data_df, pos_txt, neg_txt)\n",
        "\n",
        "  clear_output()\n",
        "  display(diagnosis_dropdown)\n",
        "\n",
        "  # Assuming 'eval_data_df' is your DataFrame with 'label' and 'score' columns\n",
        "  fpr, tpr, thresholds = roc_curve(eval_data_df['label'], eval_data_df['score'])\n",
        "  roc_auc = auc(fpr, tpr)\n",
        "\n",
        "  plt.figure()\n",
        "  lw = 2\n",
        "  plt.plot(\n",
        "      fpr,\n",
        "      tpr,\n",
        "      color=\"darkorange\",\n",
        "      lw=lw,\n",
        "      label=\"ROC curve (area = %0.2f)\" % roc_auc,\n",
        "  )\n",
        "  plt.plot([0, 1], [0, 1], color=\"navy\", lw=lw, linestyle=\"--\")\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.title(f\"ROC for {column}\")\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.show()\n",
        "  # Create a horizontal box to display image and score\n",
        "  display(widgets.HBox([\n",
        "          widgets.Label(value=\"Using positive text query\"),\n",
        "          text_input_pos,\n",
        "          clear_button_pos\n",
        "        ]))\n",
        "  display(widgets.HBox([\n",
        "        widgets.Label(value=\"Negative text query \"),\n",
        "        text_input_neg,\n",
        "        clear_button_neg\n",
        "      ]))\n",
        "  processing = False\n",
        "\n",
        "def update_plot(change):\n",
        "  draw_auc_plot(change.new)\n",
        "\n",
        "def on_text_change(change):\n",
        "  if change.new:\n",
        "    draw_auc_plot(diagnosis_dropdown.value, text_input_pos.value, text_input_neg.value)\n",
        "\n",
        "\n",
        "\n",
        "diagnosis_dropdown.observe(update_plot, names='value')\n",
        "display(diagnosis_dropdown)\n",
        "draw_auc_plot(diagnosis_dropdown.value)\n",
        "\n",
        "text_input_pos.observe(on_text_change, names='value')\n",
        "text_input_neg.observe(on_text_change, names='value')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHBM7cs5Rsj6"
      },
      "source": [
        "# Next steps\n",
        "\n",
        "Explore the other [notebooks](https://github.com/google-health/cxr-foundation/blob/master/notebooks) to learn what else you can do with the model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "d3ac608b8f9188be2227ae82298dfd5de684cbdc4496f362d4b3b9040509447c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
